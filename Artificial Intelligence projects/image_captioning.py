# -*- coding: utf-8 -*-
"""IMAGE CAPTIONING

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1J61X804NBt8tnI-k6kfzpUUko2aSeoAz
"""

pip install torch torchvision transformers pillow

import torch
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
from transformers import BlipProcessor, BlipForConditionalGeneration

# اختيار نموذج لاستخراج الميزات (VGG16 أو ResNet50)
def extract_features(image_path, model_name='vgg16'):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # تحميل النموذج
    if model_name == 'vgg16':
        model = models.vgg16(pretrained=True).features.eval().to(device)
    elif model_name == 'resnet50':
        model = models.resnet50(pretrained=True).to(device)
    else:
        raise ValueError("Select 'vgg16' or 'resnet50'")

    # تحويل الصورة
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])

    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)

    # استخراج الميزات
    with torch.no_grad():
        if model_name == 'resnet50':
            features = model(image)
        else:
            features = model(image).flatten()

    return features.cpu()

# نموذج Transformer (BLIP) لإنشاء التسمية التوضيحية
def generate_caption(image_path):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    processor = BlipProcessor.from_pretrained("Salesforce/blip-image-captioning-base")
    model = BlipForConditionalGeneration.from_pretrained("Salesforce/blip-image-captioning-base").to(device)

    image = Image.open(image_path).convert("RGB")
    inputs = processor(image, return_tensors="pt").to(device)

    with torch.no_grad():
        output = model.generate(**inputs)

    caption = processor.batch_decode(output, skip_special_tokens=True)[0]
    return caption

# تجربة الكود
image_path = "/content/ggg.jpg"  # ضع مسار الصورة هنا
features = extract_features(image_path, model_name='vgg16')  # استخراج الميزات
caption = generate_caption(image_path)  # إنشاء الوصف

print("Extracted Features Shape:", features.shape)
print("Generated Caption:", caption)

import matplotlib.pyplot as plt
img_path = "/content/ggg.jpg"
img = plt.imread(img_path)
plt.imshow(img)
plt.show()